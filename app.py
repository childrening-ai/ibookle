import streamlit as st
import json, os, datetime, gspread, uuid, pytz
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from dotenv import load_dotenv
from google import genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_pinecone import PineconeVectorStore

# ================= 1. åˆå§‹åŒ–èˆ‡ç’°å¢ƒé…ç½® =================
load_dotenv()

# è¨­å®šé é¢å±¬æ€§ (å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ Streamlit æŒ‡ä»¤)
st.set_page_config(page_title="ibookle", layout="wide", initial_sidebar_state="expanded")

# åˆå§‹åŒ– Session State
if "session_id" not in st.session_state: 
    st.session_state.session_id = str(uuid.uuid4())[:8]
if "search_results" not in st.session_state:
    st.session_state.search_results = None
if "last_row_idx" not in st.session_state:
    st.session_state.last_row_idx = None

# åˆå§‹åŒ– AI Client
if "GOOGLE_API_KEY" in st.secrets:
    client = genai.Client(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    client = None

# ================= 2. å‡½å¼å®šç¾© (æ”¾åœ¨ä¸»ç¨‹å¼å‘¼å«å‰) =================

def get_google_sheet():
    """çµ‚æ¥µæ¸…æ´—é‚è¼¯ï¼Œç¢ºä¿é€£ç·šä¸ä¸­æ–·"""
    try:
        raw_json = st.secrets["GOOGLE_CREDENTIALS"]
        try:
            creds_info = json.loads(raw_json.strip(), strict=False)
        except:
            clean_json = raw_json.replace('\n', '\\n').replace('\r', '\\r')
            creds_info = json.loads(clean_json, strict=False)
            
        scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_info, scope)
        client_gs = gspread.authorize(creds)
        return client_gs.open("AI_User_Logs").worksheet("Brief_Logs")
    except Exception as e:
        return None

def save_to_log(user_input, ai_response, recommended_books):
    """å°‡æœå°‹ç´€éŒ„å­˜å…¥ Google Sheets"""
    try:
        sheet = get_google_sheet()
        if sheet:
            tw_tz = pytz.timezone('Asia/Taipei')
            now_tw = datetime.datetime.now(tw_tz).strftime("%Y-%m-%d %H:%M:%S")
            new_row = [now_tw, st.session_state.session_id, user_input, ai_response, recommended_books, ""]
            sheet.append_row(new_row)
            return len(sheet.get_all_values())
        return None
    except:
        return None

def update_log_feedback():
    """è™•ç† ğŸ‘/ğŸ‘ å›é¥‹"""
    row_idx = st.session_state.last_row_idx
    if row_idx:
        score = st.session_state.get(f"fb_key_{row_idx}")
        if score is not None:
            try:
                sheet = get_google_sheet()
                feedback_text = "ğŸ‘" if score == 1 else "ğŸ‘"
                sheet.update_cell(row_idx, 6, feedback_text)
            except:
                pass

def get_recommendations(user_query):
    """æ‰‹å‹•æˆªæ–·ç¶­åº¦ (Dimension Fixer) çš„æœå°‹å‡½æ•¸"""
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        pinecone_key = st.secrets["PINECONE_API_KEY"]
        
        # åŸå§‹ Embedding æ¨¡å‹
        embeddings_model = GoogleGenerativeAIEmbeddings(
            model="models/gemini-embedding-001", 
            google_api_key=api_key, 
            task_type="retrieval_query"
        )
        
        # ç¶­åº¦ä¿®æ­£å™¨ï¼šå¼·åˆ¶å°‡ 3072 ç¶­åˆ‡æˆ 768 ç¶­
        class DimensionFixer:
            def __init__(self, model): self.model = model
            def embed_query(self, text): return self.model.embed_query(text)[:768]
            def embed_documents(self, texts): return [v[:768] for v in self.model.embed_documents(texts)]

        fixed_embeddings = DimensionFixer(embeddings_model)
        
        vectorstore = PineconeVectorStore(
            index_name="gemini768", 
            embedding=fixed_embeddings, 
            pinecone_api_key=pinecone_key
        )
        
        return vectorstore.similarity_search(user_query, k=5)
    except Exception as e:
        st.error(f"ğŸ” æœå°‹å¼•æ“é€£ç·šç•°å¸¸: {e}")
        return None

# ================= 3. ä¸»ç¨‹å¼é‚è¼¯ =================

# é€™è£¡å‘¼å« get_google_sheet å°±ä¸æœƒå ± NameError äº†
total_answers = "---"
sheet_for_count = get_google_sheet()
if sheet_for_count:
    try:
        total_answers = len(sheet_for_count.get_all_values()) - 1
    except:
        pass

# CSS æ¨£å¼
st.markdown("""
    <style>
    #MainMenu, footer, header {visibility: hidden; height: 0;}
    .stTextInput input { border: 2px solid #E67E22 !important; border-radius: 25px !important; }
    .expert-box { margin: 20px 0; padding: 20px; background-color: #FEF9E7; border-left: 5px solid #F39C12; border-radius: 10px; line-height: 1.8; }
    </style>
    """, unsafe_allow_html=True)

# å´é‚Šæ¬„
with st.sidebar:
    st.markdown("## ğŸ’¡ ibookle çµ±è¨ˆ")
    st.metric("ğŸ“Š å·²è§£ç­”å®¶é•·ç–‘å•", f"{total_answers} æ¬¡")
    st.divider()
    st.info("è‹¥æœ‰ä»»ä½•å»ºè­°ï¼Œæ­¡è¿é»æ“Šä¸‹æ–¹æŒ‰éˆ•å‘ŠçŸ¥æˆ‘å€‘ã€‚")

# ä¸»é é¢
st.title("ğŸ’¡ ibookle ç¹ªæœ¬å…±è®€å°ˆå®¶")
user_query = st.text_input("", placeholder="ğŸ” è¼¸å…¥å­©å­æœ€è¿‘çš„ç‹€æ³ (ä¾‹å¦‚ï¼šå­©å­ä¸æ„›æ”¶ç©å…·...)", key="main_search")

# è§¸ç™¼æœå°‹
if user_query and (not st.session_state.search_results or st.session_state.get("prev_query") != user_query):
    with st.spinner("å°ˆå®¶æ­£åœ¨æŒ‘é¸ç¹ªæœ¬..."):
        results = get_recommendations(user_query)
        if results:
            titles_str = ", ".join([d.metadata.get('Title','æœªçŸ¥') for d in results])
            prompt = f"å•é¡Œï¼š{user_query}\næ›¸ç±ï¼š{titles_str}\nè«‹ä»¥è¦ªå­å°ˆå®¶å£å»ç°¡è¿°æ¨è–¦åŸå› ã€‚ç´„150å­—ã€‚"
            
            try:
                response = client.models.generate_content(model='gemini-2.0-flash', contents=prompt)
                ai_response = response.text
                
                st.session_state.search_results = {
                    "ai_response": ai_response, 
                    "books": [{
                        "Title": d.metadata.get('Title', 'æœªçŸ¥'), 
                        "Author": d.metadata.get('Author', 'æœªçŸ¥'), 
                        "Illustrator": d.metadata.get('Illustrator', 'æœªçŸ¥'), 
                        "Quick_Summary": d.metadata.get('Quick_Summary', ''), 
                        "Refine_Content": d.metadata.get('Refine_Content', 'æš«ç„¡å°è®€'), 
                        "Link": d.metadata.get('Link', '')
                    } for d in results]
                }
                st.session_state.prev_query = user_query
                st.session_state.last_row_idx = save_to_log(user_query, ai_response, titles_str)
            except:
                st.error("AI å°ˆå®¶æš«æ™‚ç„¡æ³•å›æ‡‰ã€‚")

# é¡¯ç¤ºæœå°‹çµæœ
if st.session_state.search_results:
    res = st.session_state.search_results
    st.markdown(f'<div class="expert-box">{res["ai_response"]}</div>', unsafe_allow_html=True)
    
    st.markdown("### ğŸ“– æ¨è–¦æ›¸å–®")
    for b in res["books"]:
        with st.container():
            st.subheader(f"ã€Š{b['Title']}ã€‹")
            st.write(f"ä½œè€…ï¼š{b['Author']} | ç¹ªè€…ï¼š{b['Illustrator']}")
            if b['Quick_Summary']: st.info(b['Quick_Summary'])
            with st.expander("ğŸ” æŸ¥çœ‹è©³ç´°å°è®€"):
                st.write(b['Refine_Content'])
                if b['Link']: st.link_button("ğŸ›’ è³¼æ›¸é€£çµ", b['Link'])
        st.divider()

    if st.session_state.last_row_idx:
        st.feedback("thumbs", key=f"fb_key_{st.session_state.last_row_idx}", on_change=update_log_feedback)
else:
    st.info("ğŸ‘‹ æ­¡è¿ï¼è«‹åœ¨ä¸Šæ–¹è¼¸å…¥æ¡†æè¿°å­©å­çš„æƒ…æ³ï¼Œæˆ‘å°‡ç‚ºæ‚¨æ¨è–¦åˆé©çš„å…±è®€ç¹ªæœ¬ã€‚")